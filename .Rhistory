hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = args # supply the parallel processing counter
)
dump_features(models_list, path = "features/alex_glm_models.RData")
modelsa <- get_features("features/alex_glm_models.RData", matrixfy = F)
test <- predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],])
cor(test, auc[modelsa$cv$test_sets[[1]],1], use = "complete.obs")
modelsa$score[1,1]
test <- predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min')
cor(test, auc[modelsa$cv$test_sets[[1]],1], use = "complete.obs")
modelsa$score[1,1]
### $cv of the two benchmarking objects must match
test <- predict(modelsb$param[[1,1]][[1]], newdata = rna[modelsb$cv$test_sets[[1]],])
cor(test, auc[modelsb$cv$test_sets[[1]],1], use = "complete.obs")
modelsb$score[1,1]
test <- predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min')
cor(test, auc[modelsa$cv$test_sets[[1]],1], use = "complete.obs")
modelsa$score[1,1]
### $cv of the two benchmarking objects must match
test <- predict(modelsb$param[[1,1]][[1]], newdata = rna[modelsb$cv$test_sets[[1]],])
test
length(modelsa$cv)
length(modelsa$cv$train_sets)
lapply(1:length(modelsa$cv$train_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],]))
### $cv of the two benchmarking objects must match
test <- unlist(lapply(1:length(modelsa$cv$train_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
test
test %>% length
### $cv of the two benchmarking objects must match
test <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
test
unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,1]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')))
modelsa$param[[x,1]][[1]]
### $cv of the two benchmarking objects must match
test <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
cor(test, auc[modelsb$cv$test_sets[[1]],1], use = "complete.obs")
modelsb$score[1,1]
modelsa$param[[1,1]][[1]]
rna[modelsa$cv$test_sets[[x]],]
rna[modelsa$cv$test_sets[[1]],]
rna[modelsa$cv$test_sets[[1]],] %>% dim()
predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min')
unlist(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))
str(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))
unlist(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))
unlist(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))
unlist(list(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min')))
list(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))
unlist(predict(modelsa$param[[1,1]][[1]], newx = rna[modelsa$cv$test_sets[[1]],], s = 'lambda.min'))[,1]
test <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,1]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]))
test
### $cv of the two benchmarking objects must match
test <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
cor(test, auc[modelsb$cv$test_sets[[1]],1], use = "complete.obs")
modelsb$score[1,1]
test2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,1]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]))
test1[names(test2)]
### $cv of the two benchmarking objects must match
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
### $cv of the two benchmarking objects must match
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
test1[names(test2)]
test2[names(test1)]
cor(test, auc[,1], use = "complete.obs")
cor(test1, auc[,1], use = "complete.obs")
cor(test2, auc[,1], use = "complete.obs")
modelsa$score[,1]
test1
auc[,1]
cor(test1, auc[names(test1),1], use = "complete.obs")
modelsb$score[1,1]
cor(test2, auc[names(test2),1], use = "complete.obs")
modelsa$score[1,1]
modelsa$score[,1] %>% mean
modelsb$score[,1] %>% mean
### $cv of the two benchmarking objects must match
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],1:10])))
### $cv of the two benchmarking objects must match
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
### $cv of the two benchmarking objects must match
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,1]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])))
test2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,1]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]))
cbind(test1,test2)
cbind(test1,test2) %>% head
head(test1)
head(test2)
ncol(auc)
auc
dim(modelsa$score)
### $cv of the two benchmarking objects must match
lapply(1:ncol(auc), function(y){
test1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,y]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])));
test2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,y]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]));
temp <- cbind(test1,test2);
return(temp)
})
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/run_pipeline.R')
plot(model1, model2)
lapply(1:ncol(auc), function(y){
model1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,y]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])));
model2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,y]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]));
temp <- cbind(model1, model2);
return(temp)
})
preds_stack <- lapply(1:ncol(auc), function(y){
model1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,y]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])));
model2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,y]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]));
temp <- cbind(model1, model2);
return(temp)
})
plot(preds_stack[[1]][,1])
preds_stack[[1]][,1]
preds_stack[[1]][,2]
preds_stack[[1]]
preds_stack[[2]]
plot(preds_stack[[1]][,1],preds_stack[[1]][,2])
cor(preds_stack[[1]][,1],preds_stack[[1]][,2])
cor(preds_stack[[1]][,1],auc[,1])
plot(preds_stack[[1]][,1],auc[,1])
plot(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1])
preds_stack[[1]][,1]
auc[row.names(preds_stack[[1]]),1]
cor(preds_stack[[1]][,1],preds_stack[[1]][,2])
plot(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1], use = "complete.obs")
plot(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1], use = "complete.obs")
cor(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1], use = "complete.obs")
plot(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1])
lm(preds_stack[[1]][,1],auc[row.names(preds_stack[[1]]),1])
lm(preds_stack[[1]][,1]~auc[row.names(preds_stack[[1]]),1])
lm(preds_stack[[1]][,1]~auc[row.names(preds_stack[[1]]),1]) %>% summary
stack_features <- preds_stack[[1]]
stack_features
dev.off()
fit <- train(x = as.data.frame(x_train),
y = as.numeric(y_train),
method=customRF,
metric="RMSE",
tuneGrid=tunegrid,
trControl=control)
round(889243.1/3)
source('~/research/dream_aml/R/algorithms.R')
dump_features(stack_features, path = "features/alex_stacked_models_test.RData")
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = 10,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = args, # supply the parallel processing counter
CVBuilt = modelsa$cv
)
models_list_stacked$score
args
source('~/research/dream_aml/R/run_pipeline.R')
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = 10,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = args, # supply the parallel processing counter
CVBuilt = modelsa$cv
)
models_list_stacked$score
apply(models_list_stacked$score ,1,mean)
apply(models_list_stacked$score ,2,mean)
apply(modelsa$score ,2,mean)
apply(modelsb$score ,2,mean)
models_list_stacked$score
modelsa$score
modelsb$score
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv
)
models_list_stacked$score
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/run_pipeline.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features, this time as list orderer like the drugs in the response path file !!!
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv,
stack = T
)
stack_features
stack_features <- preds_stack
stack_features
dump_features(stack_features, path = "features/alex_stacked_models_test.RData")
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features, this time as list orderer like the drugs in the response path file !!!
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv,
stack = T
)
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
source('~/research/dream_aml/R/learning.R')
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features, this time as list orderer like the drugs in the response path file !!!
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv,
stack = T
)
source('~/research/dream_aml/R/learning.R')
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features, this time as list orderer like the drugs in the response path file !!!
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv,
stack = T
)
models_list_stacked
models_list_stacked$score
modelsa$score
modelsb$score
stack_features
stack_features[[1]]
test <- stack_features[[1]]
auc
test$auc <- auc[,1]
length(auc[,1])
dim(test)
test
test <- stack_features[[1]]
test
str(test)
test <- as.data.frame(test)
test$v3 <- auc[,1]
View(test)
head(auc[,1])
test$v3 <- auc[row.names(test),1]
test$v3 <- auc[row.names(test),1]
auc[row.names(test),1]
cor(test)
cor(test, use="obs.complete")
cor(test, use="complete.obs")
hist(auc)
dev.off()
models_list_stacked$param
models_list_stacked$param[1,1]
models_list_stacked$param[1,1][[1]][[1]]
plot(models_list_stacked$param[1,1][[1]][[1]])
dim(auc)
stack_features
test <- list(c("alpha"=0.5),list(c(333),c(500)))
test[[1]]
test[[2]]
preds_stack <- lapply(1:ncol(auc), function(y){
model1 <- unlist(lapply(1:length(modelsb$cv$test_sets), function(x) predict(modelsb$param[[x,y]][[1]], newdata = rna[modelsb$cv$test_sets[[x]],])));
model2 <- unlist(lapply(1:length(modelsa$cv$test_sets), function(x) predict(modelsa$param[[x,y]][[1]], newx = rna[modelsa$cv$test_sets[[x]],], s = 'lambda.min')[,1]));
temp <- cbind(model1, model2);
return(temp)
})
stack_features <- preds_stack
dump_features(stack_features, path = "features/alex_stacked_models_test.RData")
models_list_stacked <- run_pipeline_benchmark(
feature_path = "features/alex_stacked_models_test.RData", # path to features, this time as list orderer like the drugs in the response path file !!!
response_path = "features/alex_phenotypes_red.RData", # path to response
submission = F,
kfold = NULL,
method = "glm",
hyperparam = c("alpha"=0.5), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = NULL, # supply the parallel processing counter
CVBuilt = modelsa$cv,
stack = T
)
models_list_stacked$score
modelsa$score
models_list_stacked$score
modelsb$score
models_list_stacked$param[1,1]
models_list_stacked$param[1,1] %>% plot
models_list_stacked$param[1,1][[1]][[1]] %>% plot
models_list_stacked$param[1,2][[1]][[1]] %>% plot
models_list_stacked$param[1,3][[1]][[1]] %>% plot
models_list_stacked$param[1,3][[1]][[1]]
models_list_stacked$score
dev.off()
models_list_stacked$param[1,2][[1]][[1]]
models_list_stacked$param[1,3][[1]][[1]]
models_list_stacked$param[1,4][[1]][[1]]
models_list_stacked$param[2,2][[1]][[1]] %>% plot
models_list_stacked$param[1,2][[1]][[1]] %>% plot
coefs(models_list_stacked$param[1,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[1,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[2,1][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[1,1][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[3,1][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[5,1][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[7,1][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[1,4][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[1,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[7,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[3,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[,2][[1]][[1]], s = "lambda.min")
coef(models_list_stacked$param[8,2][[1]][[1]], s = "lambda.min")
models_list_stacked$score[,1]
plot(models_list_stacked$score[,1], modelsa$score[,1]
)
plot(models_list_stacked$score[,1], modelsb$score[,1])
plot(models_list_stacked$score[,2], modelsb$score[,2])
plot(models_list_stacked$score[,1], modelsb$score[,1])
plot(models_list_stacked$score[,1], modelsb$score[,1])+abline(a = 1)
plot(models_list_stacked$score[,1], modelsb$score[,1])+abline(a = 1, b = 0)
plot(models_list_stacked$score[,1], modelsb$score[,1])abline(a = 1, b = 0)
plot(models_list_stacked$score[,1], modelsb$score[,1]); abline(a = 1, b = 0)
plot(models_list_stacked$score[,1], modelsb$score[,1]);
abline(a = 1, b = 0)
abline(coef = c(0,1))
t.test(models_list_stacked$score[,1], modelsb$score[,1])
t.test(modelsa$score[,1], modelsb$score[,1])
plot(modelsa$score[,1], modelsb$score[,1])
abline(coef = c(0,1))
plot(modelsa$score[,2], modelsb$score[,2])
abline(coef = c(0,1))
plot(modelsa$score[,1], modelsb$score[,1])
dev.off()
dim(rna)
rna <- get_features(feature_path)
auc <- get_features(response_path)
rna
dim(rna)
auc <- get_features(response_path)
dim(auc)
dump_features(auc, path = "features/alex_phenotypes.RData")
auc <- get_features(response_path)
dim(auc)
args
dump_features(auc, path = paste0("features/alex_phenotypes_",as.character(args),".RData"))
get_features(paste0("features/alex_phenotypes_",as.character(args),".RData"),)
test <- get_features(paste0("features/alex_phenotypes_",as.character(args),".RData"),)
dim(test)
numberofargs
numberofargs <- 20 # if sequential, set to 1
source('~/research/dream_aml/R/learning.R')
rna <- get_features(feature_path)
rna <- get_features(feature_path)
dump_features(rna, path = "features/alex_features.RData")
rna <- get_features(feature_path)
auc <- get_features(response_path)
dim(rna)
dim(auc)
auc <- cut_df(auc, numberofargs,args)
source("R/general.R")
auc <- cut_df(auc, numberofargs,args)
dim(auc)
dump_features(auc, path = paste0("features/alex_phenotypes_",as.character(args),".RData"))
models_list <- run_pipeline_benchmark(
feature_path = "features/alex_features.RData", # path to features
response_path = paste0("features/alex_phenotypes_",as.character(args),".RData"), # path to response
submission = F,
kfold = 10,
method = c("dnn"),
hyperparam = NULL, #list(c(NULL,NULL)), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = 1 #args # supply the parallel processing counter
)
gadsg
a
ga
auc <- auc[,1:2]
dump_features(auc, path = paste0("features/alex_phenotypes_",as.character(args),".RData"))
args
?trainControl
source('~/research/dream_aml/R/learning.R')
models_list <- run_pipeline_benchmark(
feature_path = "features/alex_features.RData", # path to features
response_path = paste0("features/alex_phenotypes_",as.character(args),".RData"), # path to response
submission = F,
kfold = 10,
method = c("rf"),
hyperparam = list(c(NULL),c(NULL)), #list(c(333),c(500)), # c("alpha"=0.5),
cvglm = T,
returnFit = T, # if false, then it only returns the lambda
cvseed = 1 #args # supply the parallel processing counter
)
head(test$score)
test <- loadRData("~/research/dream_aml/metadata/alex/glm_test_instance1.RData")
dim(test)
test$score
ComplexHeatmap()test$score)
ComplexHeatmap(test$score)
library(ComplexHeatmap)
Heatmap(test$score)
is.na(test$score)
Heatmap(test$score)
View(test$score)
test$score[is.na(test$score)] <- 0
Heatmap(test$score)
test <- loadRData("~/research/dream_aml/metadata/alex/glm_test_instance1.RData")
mean(test%>%unlist)
mean(na.omit(test%>%unlist))
na.omit(test%>%unlist)
na.omit(test%>%unlist) %>% as.numeric()
na.omit(test$score%>%unlist) %>% as.numeric()
na.omit(test$score%>%unlist)
test$score
test$score %>% unlist
na.omit)test$score)
na.omit(test$score)
na.omit(test$score) %>% mean
as.matrix(test$score)
as.matrix(test$score) %%> unlist
as.matrix(test$score) %>% unlist
as.matrix(test$score) %>% unlist %>% mean
as.matrix(test$score) %>% unlist %>% na.omit %>%mean
as.matrix(test$score)
as.matrix(test$score)
apply(as.matrix(test$score), 1,mean)
apply(as.matrix(test$score), 1,function(x) mean(na.omit(x)))
apply(as.matrix(test$score), 1,function(x) mean(na.omit(x))) %>% mean
?cor
source('~/research/dream_aml/R/learning.R')
apply(as.matrix(test$score), 2,function(x) mean(na.omit(x)))
apply(as.matrix(test$score), 2,function(x) mean(na.omit(x))) %>% hist
apply(as.matrix(test$score), 2,function(x) mean(na.omit(x)))
apply(as.matrix(test$score), 2,function(x) mean(na.omit(x)))
test1 <0- apply(as.matrix(test$score), 2,function(x) mean(na.omit(x)))
test1 <- apply(as.matrix(test$score), 2,function(x) mean(na.omit(x)))
ttest
test1
test1 <0
test1[test1 <0] <- 0
test1
test1 %>% mean
test1
test1[test1 == NaN]
test1[test1 == "NaN"]
test1[is.na(test1)]
test1[is.na(test1)] <- 0
test1
test1 %>% mean
test
test$score
apply(test$score, 1, mean)
apply(test$score, 2, mean)
apply(test$score, 2, function(x) mean(na.omit(x)))
test1 <0 apply(test$score, 2, function(x) mean(na.omit(x)))
test1 <- apply(test$score, 2, function(x) mean(na.omit(x)))
test1[is.na(test1) & test1 <0 ] <- 0
test1
test1[is.na(test1) | test1 <0 ] <- 0
test1
hist(test1)
mean(test1)
source('~/research/dream_aml/R/learning.R')
dev.off()
